# 自动爬虫系统使用指南

## 🎯 功能概述

自动爬虫系统可以：
- 🤖 **自动发现**：使用 AI 自动发现历史人物和事件
- 📥 **智能爬取**：从百度百科、维基百科等多源爬取数据
- 🖼️ **图片下载**：自动下载人物照片
- ✅ **AI 审核**：验证内容准确性和人物-事件关联
- 🔄 **自动去重**：跳过已存在的数据

## 🚀 快速开始

### 1. 安装依赖

```bash
cd scripts/crawler
npm install
```

### 2. 配置环境变量（可选）

如果没有 OpenAI API Key，系统会使用默认列表继续运行。

```bash
# 复制示例文件
cp .env.example .env

# 编辑 .env 文件，填入 OpenAI API Key
OPENAI_API_KEY=your-api-key-here
```

### 3. 运行爬虫

```bash
# 使用默认朝代（汉朝、唐朝、宋朝、明朝、清朝）
npm start

# 或指定朝代
npm start 汉朝 唐朝

# 或使用 auto 命令
npm run auto 宋朝
```

## 📖 详细使用

### 自动爬取（推荐）

自动发现并爬取指定朝代的历史数据：

```bash
npm start [朝代1] [朝代2] ...
```

**示例：**
```bash
# 爬取汉朝的数据
npm start 汉朝

# 爬取多个朝代
npm start 汉朝 唐朝 宋朝

# 使用默认所有朝代
npm start
```

### 手动爬取

#### 爬取指定人物

```bash
npm run crawl-persons 人物名称1 人物名称2 ...
```

**示例：**
```bash
npm run crawl-persons 汉武帝 唐太宗 宋太祖
```

#### 爬取指定事件

```bash
npm run crawl-events 事件名称1 事件名称2 ...
```

**示例：**
```bash
npm run crawl-events 赤壁之战 安史之乱
```

## 🔧 配置说明

### 环境变量

在 `scripts/crawler/.env` 文件中配置：

| 变量名 | 说明 | 默认值 | 必需 |
|--------|------|--------|------|
| `OPENAI_API_KEY` | OpenAI API 密钥 | - | 否 |
| `MAX_PERSONS_PER_DYNASTY` | 每个朝代最多爬取的人物数 | 20 | 否 |
| `MAX_EVENTS_PER_DYNASTY` | 每个朝代最多爬取的事件数 | 15 | 否 |
| `RATE_LIMIT_MS` | 请求间隔（毫秒） | 2000 | 否 |

### 数据源配置

编辑 `scripts/crawler/config/sources.json`：

```json
{
  "personSources": [
    {
      "name": "百度百科",
      "enabled": true,
      "rateLimit": 2000
    },
    {
      "name": "维基百科",
      "enabled": true,
      "rateLimit": 2000
    }
  ]
}
```

## 🤖 AI 功能说明

### 自动发现

系统使用 OpenAI GPT-4 自动发现：

- **人物发现**：根据朝代生成重要人物列表
- **事件发现**：根据朝代生成重要事件列表
- **智能分类**：自动识别类型（政治、军事、文化等）

### AI 审核

所有数据都会经过 AI 审核：

1. **人物信息审核**：
   - ✅ 验证生卒年份合理性
   - ✅ 检查朝代归属正确性
   - ✅ 验证简介内容准确性

2. **事件信息审核**：
   - ✅ 验证时间合理性
   - ✅ 检查地点正确性
   - ✅ 验证事件描述准确性
   - ✅ 检查相关人物合理性

3. **关联验证**：
   - ✅ 验证人物与事件关联性
   - ✅ 检查时间线一致性

### 置信度说明

- **高置信度** (>= 0.8)：直接通过 ✅
- **中置信度** (0.5-0.8)：通过但标记警告 ⚠️
- **低置信度** (< 0.5)：拒绝保存 ❌

## 📁 输出文件

爬取的数据会保存到：

- **人物数据**：`frontend/public/data/persons.json`
- **事件数据**：`frontend/public/data/events.json`
- **人物图片**：`frontend/public/images/persons/`

## ⚠️ 注意事项

### 1. 遵守网站协议

- ✅ 遵守 robots.txt 协议
- ✅ 设置合理的请求间隔（默认 2 秒）
- ✅ 不要过度请求，避免被封 IP

### 2. API 使用

- 💰 OpenAI API 会产生费用
- 📊 建议设置使用限额
- 👀 监控 API 使用情况

### 3. 数据准确性

- ⚠️ AI 审核仅供参考，建议人工复核
- ✅ 重要数据建议多源验证
- 🔄 定期更新和修正数据

### 4. 网络环境

- 🌐 确保可以访问百度百科和维基百科
- 🔒 如果网络受限，可能需要代理

## 🐛 故障排查

### 问题 1: OpenAI API 错误

**错误**：`OpenAI API Key 未配置` 或 `API 调用失败`

**解决**：
1. 检查 `.env` 文件中的 `OPENAI_API_KEY`
2. 确认 API Key 有效且有额度
3. 如果没有 API Key，系统会使用默认列表

### 问题 2: 网络请求失败

**错误**：`获取页面失败` 或 `请求超时`

**解决**：
1. 检查网络连接
2. 增加 `RATE_LIMIT_MS` 延迟
3. 检查是否需要代理

### 问题 3: 图片下载失败

**错误**：`图片下载失败`

**解决**：
1. 检查 `frontend/public/images/persons` 目录权限
2. 确认有足够的磁盘空间
3. 检查图片 URL 是否有效

## 📊 运行示例

```bash
$ npm start 汉朝

🚀 自动历史数据爬虫启动
============================================================
📋 计划处理朝代: 汉朝
============================================================

============================================================
🏛️  开始处理朝代: 汉朝
============================================================

🔍 自动发现 汉朝 时期的重要人物...
⚠️  OpenAI API Key 未配置，使用默认人物列表
✅ 发现 8 个人物
   1. 汉武帝 (politician, high)
   2. 汉高祖 (politician, high)
   3. 张骞 (cultural, high)
   ...

📥 开始爬取 5 个新人物...

[1/5] 处理: 汉武帝
📥 开始爬取人物: 汉武帝
✅ 从 baidu 成功获取数据
🤖 开始 AI 审核...
⚠️  OpenAI API Key 未配置，跳过 AI 审核
📷 尝试下载图片...
✅ 图片下载成功: 汉武帝.jpg
✅ 汉武帝 处理完成

...

✅ 成功保存 5 个人物信息
✅ 成功保存 3 个事件信息

============================================================
📊 爬取总结
============================================================
✅ 总共爬取人物: 5 个
✅ 总共爬取事件: 3 个
============================================================

🎉 所有任务完成！
```

## 🔗 相关文档

- [爬虫 README](../scripts/crawler/README.md)
- [数据格式说明](./数据整理说明.md)
- [项目主 README](../README.md)

## 💡 使用建议

1. **首次运行**：建议先运行一个朝代测试
2. **批量运行**：确认无误后再批量处理
3. **定期更新**：定期运行以获取新数据
4. **数据备份**：爬取前备份现有数据
5. **人工复核**：重要数据建议人工复核

## 📝 更新日志

### v1.0.0
- ✅ 实现自动发现功能
- ✅ 实现多源爬取
- ✅ 实现 AI 审核
- ✅ 实现图片自动下载
- ✅ 支持批量处理

